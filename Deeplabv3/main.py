import cv2
import torch
import numpy as np
import matplotlib.pyplot as plt
import albumentations as A
from albumentations.pytorch import ToTensorV2
import time

# M√†u cho t·ª´ng l·ªõp (theo s·ªë l·ªõp c·ªßa b·∫°n)
COLORS = [
    (255, 255, 0),     # l·ªõp 0
    (0, 255, 0),       # l·ªõp 1
    (255, 0, 0),       # l·ªõp 2
    (0, 0, 255),       # l·ªõp 3
    (0, 0, 0),         # l·ªõp 4 - n·ªÅn
]

def decode_segmap(mask, num_classes):
    h, w = mask.shape
    color_mask = np.zeros((h, w, 3), dtype=np.uint8)
    for cls in range(num_classes):
        color_mask[mask == cls] = COLORS[cls]
    return color_mask

def show_prediction(model, dataset, device, idx=0, num_classes=3):
    model.eval()
    with torch.no_grad():
        image, mask = dataset[idx]  # image: CxHxW, mask: HxW
        input_tensor = image.unsqueeze(0).to(device)
        output = model(input_tensor)
        pred_mask = torch.argmax(output, dim=1).squeeze(0).cpu().numpy()

        # Unnormalize ·∫£nh
        image_np = image.permute(1, 2, 0).cpu().numpy()
        image_np = (image_np * np.array([0.229, 0.224, 0.225]) +
                    np.array([0.485, 0.456, 0.406]))
        image_np = np.clip(image_np * 255, 0, 255).astype(np.uint8)

        # Mask m√†u
        pred_color = decode_segmap(pred_mask, num_classes)
        mask_color = decode_segmap(mask.numpy(), num_classes)

        overlay = cv2.addWeighted(image_np, 0.6, pred_color, 0.4, 0)

        # Hi·ªÉn th·ªã
        plt.figure(figsize=(15, 5))
        plt.subplot(1, 4, 1)
        plt.imshow(image_np)
        plt.title("·∫¢nh g·ªëc")
        plt.axis('off')

        plt.subplot(1, 4, 2)
        plt.imshow(mask_color)
        plt.title("Mask Ground Truth")
        plt.axis('off')

        plt.subplot(1, 4, 3)
        plt.imshow(pred_color)
        plt.title("Mask D·ª± ƒëo√°n")
        plt.axis('off')

        plt.subplot(1, 4, 4)
        plt.imshow(overlay)
        plt.title("Overlay")
        plt.axis('off')

        plt.tight_layout()
        plt.show()

def analyze_position(pred):
    h, w = pred.shape
    bottom = pred[-h // 4:, :]  # 1/4 d∆∞·ªõi ·∫£nh
    unique_classes = np.unique(bottom)

    # C·∫£nh b√°o d·ª±a v√†o l·ªõp xu·∫•t hi·ªán ·ªü ph·∫ßn d∆∞·ªõi
    if 2 in unique_classes:
        print("‚ö†Ô∏è C·∫£nh b√°o: B·∫°n ƒëang ƒë·ª©ng tr√™n **ƒë∆∞·ªùng xe ch·∫°y**!")
    elif 1 in unique_classes:
        print("üö∏ B·∫°n ƒëang ƒë·ª©ng tr√™n **v·∫°ch k·∫ª ƒë∆∞·ªùng cho ng∆∞·ªùi ƒëi b·ªô**.")
    elif 3 in unique_classes:
        print("‚úÖ B·∫°n ƒëang ƒë·ª©ng tr√™n **v·ªâa h√®**.")
    else:
        print("‚ùì Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c v·ªã tr√≠ ƒë·ª©ng.")

    # X√°c ƒë·ªãnh v·ªã tr√≠ l·ªõp 1 v√† l·ªõp 3 trong to√†n ·∫£nh
    left = pred[:, :w//3]
    center = pred[:, w//3:2*w//3]
    right = pred[:, 2*w//3:]

    def find_position(region, cls):
        return cls in np.unique(region)

    for cls, name in [(1, "v·∫°ch k·∫ª ƒë∆∞·ªùng"), (3, "v·ªâa h√®")]:
        pos = []
        if find_position(left, cls):
            pos.append("b√™n tr√°i")
        if find_position(center, cls):
            pos.append("ph√≠a tr∆∞·ªõc")
        if find_position(right, cls):
            pos.append("b√™n ph·∫£i")

        if pos:
            print(f"üìç L·ªõp {cls} ({name}) xu·∫•t hi·ªán ·ªü: {', '.join(pos)}.")
        else:
            print(f"üìç L·ªõp {cls} ({name}) **kh√¥ng xu·∫•t hi·ªán** trong ·∫£nh.")

def predict_image(model_path, image_path, output_path="overlay_output.jpg", device='cuda', num_classes=4):
    # Load model
    model = load_model(model_path, num_classes=num_classes)
    model.to(device)
    model.eval()

    # Load ·∫£nh
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Resize v·ªÅ 512x384
    transform = A.Compose([
        A.Resize(384, 512),
        A.Normalize(mean=(0.485, 0.456, 0.406),
                    std=(0.229, 0.224, 0.225)),
        ToTensorV2()
    ])
    aug = transform(image=img_rgb)
    input_tensor = aug['image'].unsqueeze(0).to(device)

    # Suy lu·∫≠n
    with torch.no_grad():
        start = time.time()
        output = model(input_tensor)  # (1, C, H, W)
        pred = torch.argmax(output, dim=1).squeeze().cpu().numpy()
        end = time.time()
        print(f"‚è± Th·ªùi gian suy lu·∫≠n: {(end - start)*1000:.2f} ms")

    # Ph√¢n t√≠ch logic ƒë·ª©ng
    analyze_position(pred)

    # Overlay mask m√†u l√™n ·∫£nh
    pred_color = decode_segmap(pred, num_classes)
    pred_color_bgr = cv2.cvtColor(pred_color, cv2.COLOR_RGB2BGR)

    img_resized = cv2.resize(img, (512, 384))  # Resize ·∫£nh g·ªëc cho kh·ªõp
    overlay = cv2.addWeighted(img_resized, 0.5, pred_color_bgr, 0.5, 0)

    cv2.imwrite(output_path, overlay)
    print(f"‚úÖ Overlay ƒë√£ l∆∞u t·∫°i: {output_path}")

model_path = "deeplabv3plus_best.pth"
model = torch.load(model_path, map_location='cuda')
predict_image(model, "im1.jpg", device='cuda', num_classes=3, output_path="overlay_im1.jpg")
