# -*- coding: utf-8 -*-
"""DemoWarningWithVideo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rep3NlUMxQpsJHk06Lt_lwWV1mX5-b4Q
"""

from google.colab import drive
drive.mount('/content/gdrive')

# !pip install ultralytics
# from ultralytics import YOLO

# # Check installation
# YOLO().info()

import os

#check video availability
video_path = "/content/gdrive/MyDrive/1. Workspace/8. Google Colab/DUT5/londonstreet.mp4"

if os.path.exists(video_path):
    print(f"Video có sẵn: {video_path}")
else:
    from google.colab import files
    # upload Colab
    uploaded = files.upload()

    # check file
    video_path = list(uploaded.keys())[0]  # get name of the first file
    print(f"Video đã tải lên: {video_path}")

# Load YOLOv8
model = YOLO("yolov8n.pt")  # tiny

# Predict on video
results = model(video_path, save=True)

# get video output name
import glob
output_video = glob.glob("runs/detect/predict/*.avi")[0]
print(f"Video kết quả: {output_video}")

"""**Tích hợp BLIP để mô tả cảnh vật trong video**"""

# !pip install torch torchvision transformers

from transformers import BlipProcessor, BlipForConditionalGeneration
import torch
from PIL import Image
import requests

# Load BLIP model
processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base").to("cuda" if torch.cuda.is_available() else "cpu")

import cv2
import os

#video_path = "londonstreet.mp4"
output_folder = "frames"
os.makedirs(output_folder, exist_ok=True)

# Read video
cap = cv2.VideoCapture(video_path)
frame_rate = int(cap.get(cv2.CAP_PROP_FPS))  # frames per second
frame_count = 0

while cap.isOpened():
    success, frame = cap.read()
    if not success:
        break
    if frame_count % frame_rate == 0:  # take 1 frame/s
        frame_path = f"{output_folder}/frame_{frame_count}.jpg"
        cv2.imwrite(frame_path, frame)
    frame_count += 1

cap.release()
print("finish extract image!")

import glob

frame_paths = sorted(glob.glob(f"{output_folder}/*.jpg"))  # Danh sách ảnh

for frame_path in frame_paths:
    image = Image.open(frame_path).convert("RGB")  # Open image
    inputs = processor(image, return_tensors="pt").to("cuda" if torch.cuda.is_available() else "cpu")

    # Generate description
    caption_ids = model.generate(**inputs)
    caption = processor.batch_decode(caption_ids, skip_special_tokens=True)[0]

    print(f"{frame_path}: {caption}")

"""**Thêm logic phát hiện nguy hiểm trong YOLOv8**"""

# Threshold size for warning (adjust based on the video)
THRESHOLD_WIDTH = 200  # Example: Bounding box > 200px is considered close
THRESHOLD_HEIGHT = 200

# List of dangerous objects to warn about
dangerous_objects = ["car", "motorcycle", "bicycle", "traffic light"]

for result in results:
    for obj in result.boxes.data:
        x1, y1, x2, y2, conf, cls = obj.tolist()  # Convert tensor to list
        label = result.names[int(cls)]  # Get object name

        width = x2 - x1
        height = y2 - y1

        # Warn only when the object is close (bounding box is large)
        if label in dangerous_objects and (width > THRESHOLD_WIDTH or height > THRESHOLD_HEIGHT):
            print(f"⚠️ WARNING! Detected {label} very close!")

!pip install playsound
import playsound

def play_warning_sound():
    playsound.playsound("/content/gdrive/MyDrive/1. Workspace/8. Google Colab/DUT5/alertsound.mp3")

for result in results:
    for obj in result.boxes.data:
        x1, y1, x2, y2, conf, cls = obj.tolist()  # Convert tensor to list
        label = result.names[int(cls)]  # Get object name

        width = x2 - x1
        height = y2 - y1

        if label in dangerous_objects:
          play_warning_sound()

"""**Tích hợp Cảnh báo Giọng Nói (Text-to-Speech - TTS)**"""

#!pip install gtts
from gtts import gTTS
import os

def speak_warning(message):
    tts = gTTS(text=message, lang="vi")
    tts.save("warning.mp3")
    playsound.playsound("warning.mp3")

# detect danger, read warnings
if label in dangerous_objects:
    warning_message = f"Cảnh báo! Có {label} phía trước!"
    speak_warning(warning_message)
#không hoạt động tốt trên Google Colab hoặc môi trường Linux
##Thay playsound bằng pydub hoặc os.system("mpg321 warning.mp3") huhu

!pip install pydub
!apt-get install ffmpeg -y

from gtts import gTTS
from pydub import AudioSegment
from pydub.playback import play

def speak_warning(message):
    tts = gTTS(text=message, lang="vi")
    tts.save("warning.mp3")  # save file
    sound = AudioSegment.from_file("warning.mp3", format="mp3")
    play(sound)  # play file

speak_warning("Cảnh báo! Có xe ô tô phía trước!")

#doc truc tiep
from gtts import gTTS
from IPython.display import Audio

def speak_warning(message):
    tts = gTTS(text=message, lang="vi")
    tts.save("warning.mp3")
    return Audio("warning.mp3", autoplay=True)

if label in dangerous_objects:
    warning_message = f"Cảnh báo! Có {label} phía trước!"
    speak_warning(warning_message)

"""**Deploy DeepLabV3-MobileNetV2 để tạo Segmentation Mask (đường đi, người, xe cộ)**"""

